{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85d0aaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MLP(pl.LightningModule):\n",
    "    def __init__(self, input_features, output_features, lr=1e-3):\n",
    "        super().__init__()\n",
    "        # save hyperparameters to self.hparams automatically\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # model architecture\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_features, 1024), nn.ReLU(), nn.Dropout(0.1),\n",
    "            nn.Linear(1024, 512),          nn.ReLU(), nn.Dropout(0.1),\n",
    "            nn.Linear(512, 256),           nn.ReLU(), nn.Dropout(0.1),\n",
    "            nn.Linear(256, output_features)\n",
    "        )\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        print(\"t:y_hat's shape\", y_hat.shape)\n",
    "        print(\"t:y's shape\", y.shape)\n",
    "\n",
    "        loss = self.criterion(y_hat, y)\n",
    "\n",
    "        # log to both progress bar and wandb\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        print(\"v:y_hat's shape\", y_hat.shape)\n",
    "        print(\"v:y's shape\", y.shape)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "    \n",
    "class CNN(pl.LightningModule):\n",
    "    def __init__(self, input_features, output_features, lr=1e-3):\n",
    "        super().__init__()\n",
    "        # save hyperparameters to self.hparams automatically\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # model architecture\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 12 * 12, output_features)\n",
    "        )\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "\n",
    "        loss = self.criterion(y_hat, y)\n",
    "\n",
    "        # log to both progress bar and wandb\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "\n",
    "        loss = self.criterion(y_hat, y)\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "    \n",
    "\n",
    "def make_dataloaders(x_train, y_train, x_val, y_val, batch_size, input_features, output_features):\n",
    "    train_ds = TensorDataset(\n",
    "        torch.FloatTensor(x_train).view(-1, input_features),\n",
    "        torch.FloatTensor(y_train).view(-1, output_features)\n",
    "    )\n",
    "    val_ds = TensorDataset(\n",
    "        torch.FloatTensor(x_val).view(-1, input_features),\n",
    "        torch.FloatTensor(y_val).view(-1, output_features)\n",
    "    )\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=batch_size, shuffle=True),\n",
    "        DataLoader(val_ds, batch_size=batch_size)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2caa90fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18750"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30*25*25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a248ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataloaders_cnn(x_train, y_train, x_val, y_val, batch_size, input_features, output_features):\n",
    "    train_ds = TensorDataset(\n",
    "        torch.FloatTensor(x_train).view(-1, 6, 50, 50),\n",
    "        torch.FloatTensor(y_train).view(-1, output_features)\n",
    "    )\n",
    "    val_ds = TensorDataset(\n",
    "        torch.FloatTensor(x_val).view(-1, 6, 50, 50),\n",
    "        torch.FloatTensor(y_val).view(-1, output_features)\n",
    "    )\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=batch_size, shuffle=True),\n",
    "        DataLoader(val_ds, batch_size=batch_size)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26313c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def make_dataloaders_seq2seq(\n",
    "    train_data, val_data,\n",
    "    input_seq_len: int = 50,\n",
    "    pred_seq_len: int = 60,\n",
    "    batch_size: int = 32\n",
    "):\n",
    "    \"\"\"\n",
    "    train_data, val_data: np.ndarray of shape (N, num_agents, total_time, feat_dim)\n",
    "    We will:\n",
    "      - encoder-seq: first `input_seq_len` timesteps of *all* agents & features\n",
    "           → shape (N, input_seq_len, num_agents * feat_dim)\n",
    "      - decoder-seq: next `pred_seq_len` timesteps of agent #0, only first 2 dims\n",
    "           → shape (N, pred_seq_len, 2)\n",
    "    \"\"\"\n",
    "    def prepare(data):\n",
    "        N, A, T, F = data.shape\n",
    "        # encoder inputs: (N, A, input_seq_len, F)\n",
    "        enc = data[:, :, :input_seq_len, :]\n",
    "        # move time to dim=1: (N, input_seq_len, A, F)\n",
    "        enc = enc.transpose(1, 2)\n",
    "        # flatten agents+features → (N, input_seq_len, A*F)\n",
    "        enc = enc.reshape(N, input_seq_len, A * F)\n",
    "\n",
    "        # decoder targets: pick agent 0, dims 0:2, timesteps [input_seq_len:input_seq_len+pred_seq_len]\n",
    "        dec = data[:, 0, input_seq_len:input_seq_len + pred_seq_len, :2]\n",
    "        return enc, dec\n",
    "\n",
    "    x_tr, y_tr = prepare(train_data)\n",
    "    x_val, y_val = prepare(val_data)\n",
    "\n",
    "    train_ds = TensorDataset(\n",
    "        torch.tensor(x_tr, dtype=torch.float),\n",
    "        torch.tensor(y_tr, dtype=torch.float),\n",
    "    )\n",
    "    val_ds = TensorDataset(\n",
    "        torch.tensor(x_val, dtype=torch.float),\n",
    "        torch.tensor(y_val, dtype=torch.float),\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=batch_size, shuffle=True),\n",
    "        DataLoader(val_ds, batch_size=batch_size)\n",
    "    )\n",
    "\n",
    "class Seq2SeqLSTM(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,        # num_agents * feat_dim  (e.g. 50*6 = 300)\n",
    "        hidden_dim: int,\n",
    "        output_dim: int = 2,   # target feature size per step\n",
    "        pred_seq_len: int = 60,\n",
    "        enc_layers: int = 1,\n",
    "        dec_layers: int = 1,\n",
    "        teacher_forcing: float = 0.5,\n",
    "        lr: float = 1e-3\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # save all of these into self.hparams\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.encoder = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=enc_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.decoder = nn.LSTM(\n",
    "            input_size=output_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=dec_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.out_proj = nn.Linear(hidden_dim, output_dim)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, src, tgt=None):\n",
    "        \"\"\"\n",
    "        src: (B, in_seq_len, input_dim)\n",
    "        tgt: (B, pred_seq_len, output_dim), only used for teacher forcing\n",
    "        returns: (B, pred_seq_len, output_dim)\n",
    "        \"\"\"\n",
    "        B = src.size(0)\n",
    "        L_out = self.hparams.pred_seq_len\n",
    "        device = src.device\n",
    "\n",
    "        # run encoder\n",
    "        _, (h, c) = self.encoder(src)\n",
    "\n",
    "        # first decoder input: zeros\n",
    "        dec_input = torch.zeros(B, 1, self.hparams.output_dim, device=device)\n",
    "        outputs = torch.zeros(B, L_out, self.hparams.output_dim, device=device)\n",
    "\n",
    "        for t in range(L_out):\n",
    "            dec_out, (h, c) = self.decoder(dec_input, (h, c))\n",
    "            pred = self.out_proj(dec_out)  # (B, 1, output_dim)\n",
    "            outputs[:, t, :] = pred.squeeze(1)\n",
    "\n",
    "            # decide teacher forcing\n",
    "            if (tgt is not None) and (random.random() < self.hparams.teacher_forcing):\n",
    "                dec_input = tgt[:, t, :].unsqueeze(1)\n",
    "            else:\n",
    "                dec_input = pred\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def training_step(self, batch, _):\n",
    "        src, tgt = batch\n",
    "        pred = self(src, tgt)\n",
    "        loss = self.criterion(pred, tgt)\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, _):\n",
    "        src, tgt = batch\n",
    "        pred = self(src, None)  # no teacher forcing in val\n",
    "        loss = self.criterion(pred, tgt)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0412577f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data's shape (10000, 50, 110, 6)\n",
      "test_data's shape (2100, 50, 50, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type       | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | model     | Sequential | 558 K  | train\n",
      "1 | criterion | MSELoss    | 0      | train\n",
      "-------------------------------------------------\n",
      "558 K     Trainable params\n",
      "0         Non-trainable params\n",
      "558 K     Total params\n",
      "2.234     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x's shape torch.Size([32, 6, 50, 50])\n",
      "y's shape torch.Size([32, 120])\n",
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimmypracha/miniconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=10` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 250/250 [00:02<00:00, 101.20it/s, v_num=3, train_loss_step=1.5e+5, val_loss=7.82e+4, train_loss_epoch=7e+5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 250/250 [00:02<00:00, 100.60it/s, v_num=3, train_loss_step=1.5e+5, val_loss=7.82e+4, train_loss_epoch=7e+5]\n"
     ]
    }
   ],
   "source": [
    "input_features = 50 * 50 * 6  # = 5000\n",
    "output_features = 60 * 2\n",
    "train_file = np.load('data/train.npz')\n",
    "train_data = train_file['data']\n",
    "print(\"train_data's shape\", train_data.shape)\n",
    "test_file = np.load('data/test_input.npz')\n",
    "test_data = test_file['data']\n",
    "print(\"test_data's shape\", test_data.shape)\n",
    "train_len = int(0.8 * len(train_data))\n",
    "val_len = len(train_data) - train_len\n",
    "\n",
    "x_train, y_train = train_data[:train_len, :, :50, :], train_data[:train_len, 0, 50:, :2]\n",
    "x_val,   y_val   = train_data[train_len:, :, :50, :], train_data[train_len:, 0, 50:, :2]\n",
    "seq_train_data = train_data[:train_len, :, :50, :]\n",
    "# train_loader, val_loader = make_dataloaders_cnn(\n",
    "#     x_train, y_train, x_val, y_val, 32, \n",
    "#     input_features=input_features, output_features=output_features\n",
    "# )\n",
    "train_loader, val_loader = make_dataloaders_seq2seq(\n",
    "    seq_train_data, seq_val_data,\n",
    "    input_seq_len=50,\n",
    "    pred_seq_len=60,\n",
    "    batch_size=32\n",
    ")\n",
    "for data in train_loader:\n",
    "    x, y = data\n",
    "    print(\"x's shape\", x.shape)\n",
    "    print(\"y's shape\", y.shape)\n",
    "    break\n",
    "model = CNN(\n",
    "        input_features=input_features,\n",
    "        output_features=output_features,\n",
    "        lr=0.001\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "        max_epochs=1,\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
